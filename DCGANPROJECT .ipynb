{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing and loading the dataset"
      ],
      "metadata": {
        "id": "eLbvMDncmV8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import glob\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import cv2 as cv\n",
        "import PIL\n",
        "from PIL import Image\n",
        "!pip install plotly\n",
        "import plotly.express as px\n",
        "from IPython import display\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import torch\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp8w5hRcmVW6",
        "outputId": "6ae304e0-b18b-4e44-85d3-f6e0712f1b3c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (5.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip data"
      ],
      "metadata": {
        "id": "t716gYEamzNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a79b189f-1039-43e9-89f8-bb2b057f8817"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  data.zip\n",
            "replace imgs/imgs/0.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/'\n",
        "os.listdir(base_dir)"
      ],
      "metadata": {
        "id": "E47UDE42mgHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/txn_history-2021-10-07.jsonl'\n",
        "image_dir = \"/content/imgs/imgs\"\n",
        "image_root = \"/content/imgs\""
      ],
      "metadata": {
        "id": "S185qF4amqF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(base_dir + 'txn_history-2021-10-07.jsonl', lines=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "eJsTKWOtmshp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_plots = 10*10\n",
        "\n",
        "images = glob.glob(\"/content/imgs/imgs/*.png\")\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (30, 30)\n",
        "plt.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "print(\"Sample 100 CryptoPunks\")\n",
        "for idx,image in enumerate(images[:no_plots]):\n",
        "    sample_img = cv.imread(image)\n",
        "    plt.subplot(10, 10, idx+1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(cv.cvtColor(sample_img,cv.COLOR_BGR2RGB)) \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K8jNA6KjnIvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punks = [img for img in glob.glob(\"/content/imgs/imgs/*.png\")]\n",
        "\n",
        "for punk in punks[0:3]:\n",
        "    img = plt.imread(punk)\n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "c1FpQrAinbFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "l63uqlOInj1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[[\"txn_type\", \"date\", \"eth\", \"punk_id\", \"type\", \"accessories\"]]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qRtTAWZ5nnpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['txn_type'].unique()"
      ],
      "metadata": {
        "id": "_Jk250_xnp-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['accessories'].explode().unique()"
      ],
      "metadata": {
        "id": "pdiiB2kFnsB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['accessories'].explode().unique())"
      ],
      "metadata": {
        "id": "6rout21Tntjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.explode(\"type\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "bn0vjJhvnw3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DataLoader and Preprocess"
      ],
      "metadata": {
        "id": "DPMjrw4woFca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_imshow(img, dnorm=True):\n",
        "    img = img.to('cpu')\n",
        "    npimg = img.detach().numpy()\n",
        "    if dnorm:\n",
        "        npimg = npimg*0.5+0.5\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "CvcUydkqoCiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataloader(batch_size,           \n",
        "                   image_size,           \n",
        "                   data_dir=image_dir,   \n",
        "                   num_workers=3):       \n",
        "    \n",
        "    stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5) \n",
        "  \n",
        "    transform = transforms.Compose([transforms.Resize((image_size, image_size)),  \n",
        "                                    transforms.ToTensor(),                        \n",
        "                                    transforms.Normalize(*stats)])                \n",
        "    dataset = datasets.ImageFolder(root=data_dir,\n",
        "                                   transform=transform)\n",
        "    data_loader = torch.utils.data.DataLoader(dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              num_workers=num_workers,\n",
        "                                              pin_memory=True)\n",
        "    \n",
        "    return data_loader"
      ],
      "metadata": {
        "id": "0mDP_wKToL8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size, image_size = 5, 24\n",
        "\n",
        "train_loader = get_dataloader(batch_size,\n",
        "                              image_size,\n",
        "                              image_root)\n",
        "\n",
        "dataiter = iter(train_loader) \n",
        "img,_ = next(dataiter)\n",
        "sample_img = img[-1]\n",
        "\n",
        "tensor_imshow(sample_img)"
      ],
      "metadata": {
        "id": "hhBUF8bKoRlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Generator"
      ],
      "metadata": {
        "id": "0QT48J_-oWFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):      \n",
        "    def __init__(self, \n",
        "                 z_dim=100,      \n",
        "                 im_chan=3,      \n",
        "                 hidden_dim=64): \n",
        "        \n",
        "        super(Generator, self).__init__()\n",
        "        self.z_dim = z_dim\n",
        "        self.im_chan = im_chan\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        self.generator_cnn = nn.Sequential(self.make_gen_block(z_dim, hidden_dim*8, stride=1, padding=0),   \n",
        "                                           self.make_gen_block(hidden_dim*8, hidden_dim*4),                           \n",
        "                                           self.make_gen_block(hidden_dim*4, hidden_dim*2),                           \n",
        "                                           self.make_gen_block(hidden_dim*2, hidden_dim),                             \n",
        "                                           self.make_gen_block(hidden_dim, im_chan, final_layer=True))\n",
        "    \n",
        "    def make_gen_block(self, \n",
        "                       im_chan,    \n",
        "                       op_chan,     \n",
        "                       kernel_size=4, \n",
        "                       stride=2, \n",
        "                       padding=1, \n",
        "                       final_layer=False): \n",
        "        \n",
        "        layers = []\n",
        "        layers.append(nn.ConvTranspose2d(im_chan,     \n",
        "                                         op_chan, \n",
        "                                         kernel_size, \n",
        "                                         stride, \n",
        "                                         padding, \n",
        "                                         bias=False))\n",
        "        \n",
        "        if not final_layer:\n",
        "            layers.append(nn.BatchNorm2d(op_chan))\n",
        "            layers.append(nn.LeakyReLU(0.2))\n",
        "        else:\n",
        "            layers.append(nn.Tanh())\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def forward(self,noise):\n",
        "        x = noise.view(-1,self.z_dim,1,1)\n",
        "        return self.generator_cnn(x)\n",
        "\n",
        "    def get_noise(n_samples, \n",
        "                  z_dim, \n",
        "                  device='cpu'):\n",
        "        return torch.randn(n_samples, \n",
        "                           z_dim, \n",
        "                           device=device)"
      ],
      "metadata": {
        "id": "HdCzFHEmoTft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noise = Generator.get_noise(n_samples=5,\n",
        "                            z_dim=100)\n",
        "\n",
        "g = Generator(z_dim=100,\n",
        "              im_chan=3,\n",
        "              hidden_dim=64)"
      ],
      "metadata": {
        "id": "4A4Mq_dxoZYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(g)"
      ],
      "metadata": {
        "id": "amamfMaDoenM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nuur8id7ogOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Discrimnator"
      ],
      "metadata": {
        "id": "VGHrI4bdoifD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, \n",
        "                 im_chan=3,      \n",
        "                 conv_dim=64,     \n",
        "                 image_size=64):  \n",
        "        \n",
        "        super(Discriminator, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.conv_dim = conv_dim\n",
        "        \n",
        "        self.disc_cnn = nn.Sequential(self.make_disc_block(im_chan, conv_dim),\n",
        "                                      self.make_disc_block(conv_dim, conv_dim*2),\n",
        "                                      self.make_disc_block(conv_dim*2, conv_dim*4),\n",
        "                                      self.make_disc_block(conv_dim*4, conv_dim*8),\n",
        "                                      self.make_disc_block(conv_dim*8, 1, padding=0, final_layer=True)) \n",
        "        \n",
        "        \n",
        "    def make_disc_block(self,\n",
        "                        im_chan,\n",
        "                        op_chan,\n",
        "                        kernel_size=4,\n",
        "                        stride=2,\n",
        "                        padding=1,\n",
        "                        final_layer=False):\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(im_chan,\n",
        "                                op_chan,\n",
        "                                kernel_size,\n",
        "                                stride,\n",
        "                                padding,\n",
        "                                bias=False))\n",
        "        \n",
        "        if not final_layer:\n",
        "            layers.append(nn.BatchNorm2d(op_chan))\n",
        "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "        \n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self,image):\n",
        "        pred = self.disc_cnn(image)\n",
        "        pred = pred.view(image.size(0),-1)\n",
        "        return pred\n",
        "    \n",
        "    def _get_final_feature_dimention(self):\n",
        "        final_width_height = (self.image_size //  2**len(self.disc_cnn))**2\n",
        "        final_depth = self.conv_dim * 2**(len(self.disc_cnn)-1)\n",
        "        return final_depth*final_width_height"
      ],
      "metadata": {
        "id": "I8Il7QqWopZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = Discriminator(im_chan=3,\n",
        "                  conv_dim=64,\n",
        "                  image_size=64)"
      ],
      "metadata": {
        "id": "XXxnNPKJospE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(d)"
      ],
      "metadata": {
        "id": "JZuV5Hffoug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Training Parameters"
      ],
      "metadata": {
        "id": "RgaGzHCLo2cw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    \n",
        "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02) \n",
        "        \n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "KqPoRrfjow0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def real_loss(D_out,device='cpu'):\n",
        "    \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "\n",
        "    batch_size = D_out.size(0)\n",
        " \n",
        "    labels = torch.ones(batch_size, device=device)*0.9 \n",
        "    \n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "IImU-wDOo3ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fake_loss(D_out, device='cpu'):\n",
        "    \n",
        " \n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    \n",
        "  \n",
        "    batch_size = D_out.size(0)\n",
        "    \n",
        "    labels = torch.zeros(batch_size,\n",
        "                         device=device) \n",
        "    \n",
        "    loss = criterion(D_out.squeeze(), labels)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "3ncAUn4vo8kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training "
      ],
      "metadata": {
        "id": "xmmlTOPzo--I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_tensor_images(images_tensor):\n",
        "    \n",
        "    '''\n",
        "    Function for visualizing images: Given a tensor of images, prints the images.\n",
        "    '''\n",
        "        \n",
        "    plt.rcParams['figure.figsize'] = (15, 15)\n",
        "    plt.subplots_adjust(wspace=0, hspace=0)\n",
        "    \n",
        "    images_tensor = images_tensor.to('cpu')\n",
        "    npimgs = images_tensor.detach().numpy()\n",
        "    \n",
        "    no_plots = len(images_tensor)\n",
        "\n",
        "    for idx,image in enumerate(npimgs):\n",
        "        plt.subplot(1, 8, idx+1)\n",
        "        plt.axis('off')\n",
        "        image = image * 0.5 + 0.5\n",
        "        plt.imshow(np.transpose(image, (1, 2, 0)))\n",
        "        \n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LFHBfiOwo-U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(D, G, \n",
        "          n_epochs,\n",
        "          dataloader,\n",
        "          d_optimizer,\n",
        "          g_optimizer,\n",
        "          z_dim,\n",
        "          print_every=50,\n",
        "          device='cpu'):\n",
        "    \n",
        "    sample_size=8\n",
        "    fixed_z = Generator.get_noise(n_samples=sample_size,\n",
        "                                  z_dim=z_dim,\n",
        "                                  device=device)\n",
        "    \n",
        "    for epoch in range(1,n_epochs+1):\n",
        "        for batch_i,(real_images,_) in enumerate(dataloader):\n",
        "            batch_size = real_images.size(0)\n",
        "            real_images = real_images.to(device)\n",
        "            \n",
        "            d_optimizer.zero_grad()\n",
        "\n",
        "            d_real_op = D(real_images)\n",
        "            d_real_loss = real_loss(d_real_op,\n",
        "                                    device=device)\n",
        "\n",
        "            noise = Generator.get_noise(n_samples=batch_size,\n",
        "                                        z_dim=z_dim,\n",
        "                                        device=device)\n",
        "            fake_images = G(noise)\n",
        "\n",
        "            d_fake_op = D(fake_images) \n",
        "            d_fake_loss = fake_loss(d_fake_op,\n",
        "                                    device=device)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "            \n",
        "       \n",
        "            d_loss.backward()\n",
        "            d_optimizer.step()\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            noise = Generator.get_noise(n_samples=batch_size,\n",
        "                                        z_dim=z_dim,\n",
        "                                        device=device)\n",
        "\n",
        "            g_out = G(noise)\n",
        "            d_out = D(g_out)\n",
        "            \n",
        "            g_loss = real_loss(d_out, \n",
        "                               device=device) \n",
        "            g_loss.backward()\n",
        "            g_optimizer.step()\n",
        "        \n",
        "        print('Epoch [{:5d}/{:5d}] | d_loss: {:6.4f} | g_loss: {:6.4f}'.format(epoch, \n",
        "                                                                               n_epochs, \n",
        "                                                                               d_loss.item(),  \n",
        "                                                                               g_loss.item())) \n",
        "        if (epoch % print_every == 0):\n",
        "            G.eval()\n",
        "            sample_image = G(fixed_z)\n",
        "            print_tensor_images(sample_image)\n",
        "            G.train()"
      ],
      "metadata": {
        "id": "rCszKlzspAsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device is \", device)\n",
        "\n",
        "z_dim = 100       \n",
        "beta_1 = 0.5    \n",
        "beta_2 = 0.999 \n",
        "lr = 0.0002      \n",
        "n_epochs = 100\n",
        "batch_size = 128\n",
        "image_size = 64"
      ],
      "metadata": {
        "id": "0wnMaoQ_pGei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim, \n",
        "                      im_chan=3, \n",
        "                      hidden_dim=64).to(device)\n",
        "\n",
        "discriminator = Discriminator(im_chan=3, \n",
        "                              conv_dim=64, \n",
        "                              image_size=image_size).to(device)\n",
        "\n",
        "g_optimizer = optim.Adam(generator.parameters(), \n",
        "                         lr=lr, \n",
        "                         betas=(beta_1, beta_2))\n",
        "\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), \n",
        "                         lr=lr, \n",
        "                         betas=(beta_1, beta_2))\n",
        "\n",
        "dataloader = get_dataloader(batch_size, \n",
        "                            image_size, \n",
        "                            image_root)"
      ],
      "metadata": {
        "id": "xt8U5NWwpJt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "n_epochs = 100\n",
        "train(discriminator,\n",
        "      generator,\n",
        "      n_epochs,\n",
        "      dataloader,\n",
        "      d_optimizer,\n",
        "      g_optimizer,\n",
        "      z_dim,\n",
        "      print_every=10,\n",
        "      device=device)"
      ],
      "metadata": {
        "id": "aqzsYPx8pM3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (15, 8))\n",
        "plt.plot(noise)\n",
        "plt.title(\"Noise\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tra3WcSUpOy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create new cryptopunks"
      ],
      "metadata": {
        "id": "VVJ8LKFupVwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator.to(device)\n",
        "generator.eval()      \n",
        "sample_size=8\n",
        "\n",
        "for i in range(8):    \n",
        "    \n",
        "    fixed_z = Generator.get_noise(n_samples=sample_size, \n",
        "                                  z_dim=z_dim, \n",
        "                                  device=device)    \n",
        "    \n",
        "    sample_image = generator(fixed_z)\n",
        "\n",
        "    print_tensor_images(sample_image)"
      ],
      "metadata": {
        "id": "0Zu1qu5EpW8_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}